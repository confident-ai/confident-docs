---
slug: integrations/opentelemetry
---

[OpenTelemetry](https://opentelemetry.io/docs/what-is-opentelemetry/) is an open-source observability framework that allows teams to collect, analyze, and visualize telemetry data. 

## Overview

**Confident AI** can recieve traces on `https://otel.confident-ai.com`. To export traces using the OpenTelemetry SDK, you can configure your Collector with the official open-telemetry library.

<Note>
If your configration requires signal specific environment variable, set the trace endpoint to `https://otel.confident-ai.com/v1/traces`.
</Note>

## Quickstart

Given below is the quickstart for exporting traces to Confident AI OTLP endpoint (which will then published to **observatory**) for different languages.

<Steps>

    <Step title="Set Environment Variables">
        First set your `CONFIDENT_API_KEY` and `OTEL_EXPORTER_OTLP_ENDPOINT` as an enviornment variable:

        ```bash title="Bash"
        export CONFIDENT_API_KEY="confident_us..."
        export OTEL_EXPORTER_OTLP_ENDPOINT="https://otel.confident-ai.com"
        ```
    </Step>

    <Step title="Trace your first LLM application">

        <Tabs>

            <Tab title="Python">
                Install opentelemetry dependencies:

                ```bash title="Bash"
                pip install opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp-proto-http
                ```

                Run the following code:

                ```python title="main.py"
                import os

                from opentelemetry.sdk.trace import TracerProvider
                from opentelemetry.sdk.trace.export import BatchSpanProcessor
                from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter

                OTLP_ENDPOINT = os.getenv("OTEL_EXPORTER_OTLP_ENDPOINT")
                CONFIDENT_API_KEY = os.getenv("CONFIDENT_API_KEY")

                trace_provider = TracerProvider()
                exporter = OTLPSpanExporter(
                    endpoint=f"{OTLP_ENDPOINT}/v1/traces",
                    headers={"x-confident-api-key": CONFIDENT_API_KEY},
                )
                span_processor = BatchSpanProcessor(span_exporter=exporter)
                trace_provider.add_span_processor(span_processor)
                tracer = trace_provider.get_tracer("deepeval_tracer")

                # Start a span
                with tracer.start_as_current_span("confident-llm-span") as span:
                    
                    # Set attributes
                    span.set_attribute("confident.trace.name", "example-trace")
                    span.set_attribute("confident.span.type", "llm")
                    span.set_attribute("confident.llm.model", "gpt-4o")
                    span.set_attribute("confident.span.input", "What is the capital of France?")
                    span.set_attribute("confident.span.output", "Paris")
                
                trace_provider.force_flush()
                print("Traces posted successfully to https://otel.confident-ai.com")
                ```

                Run the code:

                ```bash
                python main.py
                ```

                <Note>
                The above example creates a new OpenTelemetry trace provider and sets `OTLPSpanExporter` to it so that the spans are exported to the Confident AI OTLP endpoint ONLY. If you wish to set `OTLPSpanExporter` to the existing OpenTelemetry trace provider, refer to the following example.
                </Note>

                <Accordion title="Click here to know how to set `OTLPSpanExporter` to the existing OpenTelemetry trace provider">

                ```python title="main.py"
                from opentelemetry import trace
                from opentelemetry.sdk.trace import TracerProvider
                from opentelemetry.sdk.trace.export import BatchSpanProcessor
                from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter


                OTLP_ENDPOINT = os.getenv("OTEL_EXPORTER_OTLP_ENDPOINT")
                CONFIDENT_API_KEY = os.getenv("CONFIDENT_API_KEY")

                # Setup OpenTelemetry
                if not isinstance(trace.get_tracer_provider(), TracerProvider):
                    tracer_provider = TracerProvider()
                    trace.set_tracer_provider(tracer_provider)
                else:
                    tracer_provider = trace.get_tracer_provider()

                exporter = OTLPSpanExporter(
                    endpoint=f"{OTLP_ENDPOINT}/v1/traces",
                    headers={"x-confident-api-key": CONFIDENT_API_KEY},
                )

                span_processor = BatchSpanProcessor(span_exporter=exporter)
                tracer_provider.add_span_processor(span_processor)
                tracer = trace.get_tracer("deepeval_tracer")

                ```
                </Accordion>

            </Tab>

            <Tab title="TypeScript">
                Install Node.js dependencies

                ```bash
                npm init -y
                npm install @opentelemetry/api @opentelemetry/sdk-trace-node @opentelemetry/sdk-trace-base @opentelemetry/exporter-trace-otlp-proto dotenv
                ```

                Install TypeScript and ts-node

                ```bash
                npm install -D typescript ts-node @types/node
                ```

                Create `index.ts` file. This file contains the code for creating an LLM span.

                ```typescript title="index.ts"
                import * as opentelemetry from '@opentelemetry/api';
                import { NodeTracerProvider } from '@opentelemetry/sdk-trace-node';
                import { BatchSpanProcessor } from '@opentelemetry/sdk-trace-base';
                import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-proto';

                // Environment variables (similar to Python's os.getenv)
                const OTLP_ENDPOINT = process.env.OTEL_EXPORTER_OTLP_ENDPOINT;
                const CONFIDENT_API_KEY = process.env.CONFIDENT_API_KEY;

                // Add validation for required environment variables
                if (!OTLP_ENDPOINT) {
                    throw new Error('OTEL_EXPORTER_OTLP_ENDPOINT environment variable is required');
                }

                // Create OTLP exporter with HTTPS support
                const otlpExporter = new OTLPTraceExporter({
                    url: `${OTLP_ENDPOINT}/v1/traces`,
                    headers: {
                        'x-confident-api-key': CONFIDENT_API_KEY || ''
                    },
                });

                // Set up the tracer provider with the batch span processor
                const provider = new NodeTracerProvider({
                    spanProcessors: [new BatchSpanProcessor(otlpExporter)]
                });

                // Register the provider globally
                opentelemetry.trace.setGlobalTracerProvider(provider);

                // Create a tracer
                const tracer = opentelemetry.trace.getTracer('confident-llm-tracer');

                async function main() {
                    // Start a span
                    tracer.startActiveSpan('confident-llm-span-typescript', (span) => {
                        // Set attributes
                        span.setAttributes({
                            'confident.trace.name': 'example-trace',
                            'confident.span.type': 'llm',
                            'confident.llm.model': 'gpt-4o',
                            'confident.span.input': 'What is the capital of France?',
                            'confident.span.output': 'Paris'
                        });

                        // Simulate some work here
                        console.log('Processing LLM request...');

                        // End the span
                        span.end();
                    });

                    // Shut down the provider to ensure traces are flushed before the script exits
                    await provider.shutdown();
                    console.log(`Trace posted successfully to ${OTLP_ENDPOINT}.`);
                }

                main().catch((error) => {
                    console.error('Error sending traces:', error);
                    process.exit(1);
                });
                ```

                Create a basic `tsconfig.json` file:

                ```json title="tsconfig.json"
                {
                    "compilerOptions": {
                        "target": "ES2020",
                        "module": "commonjs",
                        "esModuleInterop": true,
                        "skipLibCheck": true,
                        "forceConsistentCasingInFileNames": true,
                        "outDir": "./dist"
                    }
                }
                ```

                Run the code:

                ```bash
                npx ts-node index.ts
                ```
            </Tab>

            <Tab title="Go">
                Install Go (version 1.19 or later recommended):

                Set up environment variables:

                ```bash
                export OTLP_ENDPOINT="otel.confident-ai.com"
                export CONFIDENT_API_KEY="<your-confident-api-key>"
                ```

                Initialize Go Module:

                ```bash
                go mod init go-example
                ```

                Create `main.go` file.

                ```go title="main.go"
                package main

                import (
                    "context"
                    "fmt"
                    "log"
                    "os"

                    "go.opentelemetry.io/otel"
                    "go.opentelemetry.io/otel/attribute"
                    "go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp"
                    "go.opentelemetry.io/otel/propagation"
                    sdktrace "go.opentelemetry.io/otel/sdk/trace"
                )

                func main() {
                    endpoint := os.Getenv("OTLP_ENDPOINT")
                    confidentApiKey := os.Getenv("CONFIDENT_API_KEY")

                    exporter, err := otlptracehttp.New(context.Background(),
                        otlptracehttp.WithEndpoint(endpoint),
                        otlptracehttp.WithHeaders(map[string]string{"x-confident-api-key": confidentApiKey}),
                    )
                    if err != nil {
                        log.Fatalf("failed to create OTLP exporter: %v", err)
                    }

                    tp := sdktrace.NewTracerProvider(sdktrace.WithBatcher(exporter))
                    otel.SetTracerProvider(tp)
                    otel.SetTextMapPropagator(propagation.TraceContext{})
                    defer func() { 
                        fmt.Println("Shutting down tracer provider...")
                        _ = tp.Shutdown(context.Background()) 
                    }()

                    _, span := otel.Tracer("example.com/otel-openai").Start(context.Background(), "chat gpt-4o")
                    defer func() {
                        span.End()
                        fmt.Println("Span ended - Trace posted successfully to:", endpoint)
                    }()

                    span.SetAttributes(
                        attribute.String("confident.span.type", "llm"),
                        attribute.String("confident.llm.model", "gpt-4o"),
                        attribute.String("confident.span.input", "input"),
                        attribute.String("confident.span.output", "output"),
                    )
                    
                }
                ```

                Install dependencies:

                ```bash
                go mod tidy
                ```

                Run the code:

                ```bash
                go run main.go
                ```
            </Tab>

            <Tab title="Ruby">
            Create `Gemfile` file. This file contains the dependencies for the Ruby application.

            ```ruby title="Gemfile"
            source 'https://rubygems.org'

            gem 'opentelemetry-sdk'
            gem 'opentelemetry-exporter-otlp'
            ```

            Install dependencies:

            ```bash
            bundle install
            ```

            Create `example.rb` file. This file contains the code for creating an LLM span.

            ```ruby title="example.rb"
            require 'opentelemetry/sdk'
            require 'opentelemetry/exporter/otlp'

            # Ensure OTLP endpoint and API key are set
            OTLP_ENDPOINT    = ENV.fetch('OTEL_EXPORTER_OTLP_ENDPOINT') { abort 'Set OTEL_EXPORTER_OTLP_ENDPOINT' }
            CONFIDENT_API_KEY = ENV.fetch('CONFIDENT_API_KEY')       { abort 'Set CONFIDENT_API_KEY' }

            OpenTelemetry::SDK.configure do |c|
            c.add_span_processor(
                OpenTelemetry::SDK::Trace::Export::BatchSpanProcessor.new(
                OpenTelemetry::Exporter::OTLP::Exporter.new(
                    endpoint: "#{OTLP_ENDPOINT}/v1/traces",
                    headers:  { 'x-confident-api-key' => CONFIDENT_API_KEY },
                )
                )
            )
            end

            tracer = OpenTelemetry.tracer_provider.tracer(__FILE__)

            tracer.in_span('confident-llm-span-ruby') do |span|
                span.set_attribute('confident.trace.name', 'example-trace')
                span.set_attribute('confident.span.type', 'llm')
                span.set_attribute('confident.llm.model', 'gpt-4o')
                span.set_attribute('confident.span.input', 'What is the capital of France?')
                span.set_attribute('confident.span.output', 'Paris')

                puts 'Span created successfully!'
            end

            # Flush and allow time for HTTP export
            OpenTelemetry.tracer_provider.shutdown
            puts "Traces posted successfully to #{OTLP_ENDPOINT}."
            sleep 2
            ```

            Run the code:

            ```bash
            ruby example.rb
            ```
            </Tab>

            <Tab title="C#">
            
            Create a New Console App

            ```bash
            dotnet new console -n ConfidentLLMExample
            cd ConfidentLLMExample
            ```

            Add Required NuGet Packages

            ```bash
            dotnet add package OpenTelemetry
            dotnet add package OpenTelemetry.Exporter.OpenTelemetryProtocol
            ```

            Create `Program.cs` file. This file contains the code for creating an LLM span.

            ```csharp title="Program.cs"
            using System;
            using OpenTelemetry;
            using OpenTelemetry.Trace;
            using OpenTelemetry.Resources;
            using OpenTelemetry.Exporter;
            using System.Threading.Tasks;

            class Program
            {
                static async Task Main(string[] args)
                {
                    var otlpEndpoint = Environment.GetEnvironmentVariable("OTEL_EXPORTER_OTLP_ENDPOINT");
                    var confidentApiKey = Environment.GetEnvironmentVariable("CONFIDENT_API_KEY");

                    Console.WriteLine($"OTLP Endpoint: {otlpEndpoint}");
                    Console.WriteLine($"API Key configured: {!string.IsNullOrEmpty(confidentApiKey)}");

                    using var tracerProvider = Sdk.CreateTracerProviderBuilder()
                        .SetResourceBuilder(ResourceBuilder.CreateDefault()
                            .AddService("ConfidentLLMService"))
                        .AddSource("ConfidentLLMTracer")
                        .AddOtlpExporter(options =>
                        {
                            options.Endpoint = new Uri($"{otlpEndpoint}/v1/traces");
                            options.Headers = $"x-confident-api-key={confidentApiKey}";
                            options.Protocol = OtlpExportProtocol.HttpProtobuf;
                            // Add timeout and retry configuration
                            options.TimeoutMilliseconds = 30000;
                        })
                        .Build();

                    var tracer = tracerProvider.GetTracer("ConfidentLLMTracer");

                    Console.WriteLine("Starting span...");
                    using (var currentSpan = tracer.StartActiveSpan("confident-llm-span-csharp"))
                    {
                        currentSpan.SetAttribute("confident.trace.name", "example-trace");
                        currentSpan.SetAttribute("confident.span.type", "llm");
                        currentSpan.SetAttribute("confident.llm.model", "gpt-4o");
                        currentSpan.SetAttribute("confident.span.input", "What is the capital of France?");
                        currentSpan.SetAttribute("confident.span.output", "Paris");

                        Console.WriteLine("Span created with attributes. It will end after 5 seconds.");
                        await Task.Delay(5000);
                    }

                    Console.WriteLine("Span ended. Flushing traces...");
                    
                    // Force flush traces before exiting
                    tracerProvider.ForceFlush();
                    
                    // Wait a bit to ensure traces are sent
                    await Task.Delay(2000);
                    Console.WriteLine($"Trace posted successfully to {otlpEndpoint}.");
                }
            }
            ```

            Build and Run

            ```bash
            dotnet run
            ```
            
            </Tab>
            
        </Tabs>

    </Step>

</Steps>

ðŸŽ‰ Congratulations! You have successfully sent traces. Go to the the Observatory section on Confident AI to check it out.

<Accordion title="Click to see native python implementation using DeepEval">
DeepEval provides a native `ConfidentSpanExporter` that directly exports traces to Confident AI **observatory**.

```python title="example.py"
import time
import json
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

from deepeval.tracing.otel.exporter import ConfidentSpanExporter

# Set up tracer provider
tracer_provider = trace.get_tracer_provider()
if not isinstance(tracer_provider, TracerProvider):
    trace.set_tracer_provider(TracerProvider())

# Add confident span exporter wrapped in batch span processor
tracer_provider.add_span_processor(BatchSpanProcessor(ConfidentSpanExporter()))

# Get tracer
tracer = trace.get_tracer("deepeval_tracer")

# set attributes
with tracer.start_as_current_span("confident-llm-span") as span:
    span.set_attribute("confident.trace.name", "example-trace")
    span.set_attribute("confident.span.type", "llm")
    span.set_attribute("confident.llm.model", "gpt-4o")
    span.set_attribute("confident.span.input", "What is the capital of France?")
    span.set_attribute("confident.span.output", "Paris")
```
</Accordion>

## Understanding OTEL with Confident AI

In this section, we will mainly discuss:

- `gen_ai` attribute and event conventions
- Confident AI specific conventions
- Advanced configurations

### OTEL endpoints

Confident AI offers the `https://otel.confident-ai.com` endpoint that accepts OpenTelemetry traces in the [OTLP format](https://opentelemetry.io/docs/specs/otlp/#otlphttp). Please note that Confident AI does **not support** GRPC for the OpenTelemetry endpoint. Please use HTTP instead.

### Attributes

**Confident AI** adheres to the [GenAI semantic convention](https://opentelemetry.io/docs/specs/semconv/gen-ai/) and adds an extra layer on top of it to capture additional data about the LLM applications. Confident AI uses `confident.*` namespace to map specific attributes with [llm tracing](/docs/llm-tracing/introduction) data model. These specific attributes always take precedence over `gen_ai.*` conventions and are recommended for all users that are manually instrumenting their applications.

<Warning>
The **GenAI semantic conventions** are still under development and are subject to change.
</Warning>

### Advanced configurations

The [enviornment](/llm-tracing/advanced-features/environment) allows you to configure where your trace belongs on Confident AI (defaulted to `"development"`). You can configure the enviornment and sampling rate of traces by setting the following two enviornment variables:

```bash
OTEL_RESOURCE_ATTRIBUTES="confident.trace.environment=production"
```
## Trace-Level Attribute Mappings

These are the attributes specific to Confident AI traces similar to [tracing features](/docs/llm-tracing/advanced-features/attributes). The trace level attributes are set in the span attributes using the `confident.trace.*` namespace.

<Info>
It is recommended to set trace attributes once in any span in a trace lifecycle. The value of the **specific attribute** will be updated to the latest value if set in multiple spans.
</Info>

### Name

The trace name is displayed in the UI. You can customize it based on your liking for better UI display using the following attribute:

- `"confident.trace.name"` (of type `str`) used for updating trace [name](/docs/llm-tracing/advanced-features/name)

<CodeBlocks>
```python
with tracer.start_as_current_span("custom_span") as span:
    span.set_attribute("confident.trace.name", "test_trace")
```

```typescript
span.setAttributes({
    "confident.trace.name": "example-trace",
});
```

```go
span.SetAttributes(
    attribute.String("confident.trace.name", "example-trace"),
)
```

```ruby
span.setAttributes({
    "confident.trace.name": "example-trace",
});
```

```csharp
span.SetAttribute("confident.trace.name", "example-trace");
```

</CodeBlocks>

### Input/Output

You can set [trace input and output](/docs/llm-tracing/advanced-features/input-output#set-trace-io-at-runtime) at runtime using the following attributes:

- `"confident.trace.input"` (of type `Any`) used for updating trace input
- `"confident.trace.output"` (of type `Any`) used for updating trace output

<CodeBlocks>

```python
with tracer.start_as_current_span("custom_span") as span:
    span.set_attribute("confident.trace.input", input)
    span.set_attribute("confident.trace.output", output)
```

```typescript
span.setAttributes({
    "confident.trace.input": input,
    "confident.trace.output": output,
});
```

```go
span.SetAttributes(
    attribute.String("confident.trace.input", input),
    attribute.String("confident.trace.output", output),
)
```

```ruby
span.setAttributes({
    "confident.trace.input": input,
    "confident.trace.output": output,
});
```

```csharp
span.SetAttribute("confident.trace.input", input);
span.SetAttribute("confident.trace.output", output);
```

</CodeBlocks>

### Test Case

[LLM Test Case](/docs/llm-tracing/advanced-features/test-cases) attributes can be used to unit test interactions within your LLM application. It can be set in the span as **trace level attributes** using the `confident.trace.llm_test_case.*` namespace.

Given below is the example of running [online evaluation](/docs/llm-tracing/evaluations#online-evaluations) for a span.

<CodeBlocks>

```python
with tracer.start_as_current_span("confident_evaluation") as span:
    input = "What is the capital of France?"
    output = my_llm_app(input)
    
    span.set_attribute('confident.trace.metric_collection', "<your_metric_collection>")
    span.set_attribute('confident.trace.llm_test_case.input', input)
    span.set_attribute('confident.trace.llm_test_case.actual_output', output)
```

```typescript
span.setAttributes({
    "confident.trace.metric_collection": "<your_metric_collection>",
    "confident.trace.llm_test_case.input": input,
    "confident.trace.llm_test_case.actual_output": output,
});
```

```go
span.SetAttributes(
    attribute.String("confident.trace.metric_collection", "<your_metric_collection>"),
    attribute.String("confident.trace.llm_test_case.input", input),
    attribute.String("confident.trace.llm_test_case.actual_output", output),
)
```

```ruby
span.setAttributes({
    "confident.trace.metric_collection": "<your_metric_collection>",
    "confident.trace.llm_test_case.input": input,
    "confident.trace.llm_test_case.actual_output": output,
});
```

```csharp
span.SetAttribute("confident.trace.metric_collection", "<your_metric_collection>");
span.SetAttribute("confident.trace.llm_test_case.input", input);
span.SetAttribute("confident.trace.llm_test_case.actual_output", output);
```

</CodeBlocks>

<Info>
Make sure you have [metric collection](/docs/metrics/metric-collections) created on the platform for running online evaluation on this test case.
</Info>

LLM test case attributes mapping:

- `"confident.trace.llm_test_case.input"` (of type `str`) used for updating test case input
- `"confident.trace.llm_test_case.actual_output"` (of type `str`) used for updating test case actual output
- [Optional] `"confident.trace.llm_test_case.expected_output"` (of type `str`) used for updating test case expected output
- [Optional] `"confident.trace.llm_test_case.context"` (of type `list[str]`) used for updating test case context
- [Optional] `"confident.trace.llm_test_case.retrieval_context"` (of type `list[str]`) used for updating test case retrieval context
- [Optional] `"confident.trace.llm_test_case.tools_called"` (of type `str`) used for updating test case tools called
- [Optional] `"confident.trace.llm_test_case.expected_tools"` (of type `str`) used for updating test case expected tools

### Tags

[Tags](/docs/llm-tracing/advanced-features/tags) are simple string labels that make it easy to group related traces together, and cannot be applied to spans.

- `"confident.trace.tags"` (of type `list[str]`) used for updating trace tags

<CodeBlocks>

```python
with tracer.start_as_current_span("custom_span") as span:
    span.set_attribute("confident.trace.tags", ["tag1", "tag2"])
```

```typescript
span.setAttributes({"confident.trace.tags": ["tag1", "tag2"]});
```

```go
span.SetAttributes(
    attribute.StringSlice("confident.trace.tags", []string{"tag1", "tag2"}),
)
```

```ruby
span.set_attribute('confident.trace.tags', ['tag1', 'tag2'])
```

```csharp
currentSpan.SetAttribute("confident.trace.tags", new[] { "tag1", "tag2" });
```

</CodeBlocks>

### Metadata

Attach [metadata](/docs/llm-tracing/advanced-features/metadata) to the trace. This information can be used for filtering, grouping, and analyzing your traces in the observatory.

- `"confident.trace.metadata"` (of type `str`) used for updating trace metadata

This attribute is a JSON string which is parsed into a dictionary.

<CodeBlocks>

```python
import json

with tracer.start_as_current_span("custom_span") as span:
    span.set_attribute("confident.trace.metadata", json.dumps({"key": "value"}))
```

```typescript
span.setAttributes({
    'confident.trace.metadata': JSON.stringify({ key: "value" }),
});
```

```go
attribute.String("confident.trace.metadata", `{"key": "value"}`)
```

```ruby
span.setAttributes({
    "confident.trace.metadata": `{"key": "value"}`,
});
```

```csharp
span.set_attribute('confident.trace.metadata', '{"key": "value"}');
```

</CodeBlocks>

### Thread id

A [thread](/docs/llm-tracing/advanced-features/threads) on Confident AI is a collection of one or more traces, letting you view full conversations â€” perfect for chat apps, agents, or any multi-turn interactions.

- `"confident.trace.thread_id"` (of type `str`) used for updating trace **thread id**

<CodeBlocks>

```python
with tracer.start_as_current_span("custom_span") as span:
    span.set_attribute("confident.trace.thread_id", "123")
```

```typescript
span.setAttributes({
    "confident.trace.thread_id": "123",
});
```

```go
span.SetAttributes(
    attribute.String("confident.trace.thread_id", "123"),
)
```

```ruby
span.setAttributes({
    "confident.trace.thread_id": "123",
});
```

```csharp
span.SetAttribute("confident.trace.thread_id", "123");
```

</CodeBlocks>

### User Id

Track user interactions by setting [user id](/docs/llm-tracing/advanced-features/users) in a trace â€” useful for monitoring token usage, identifying top users, and managing costs.

- `"confident.trace.user_id"` (of type `str`) used for updating trace user id

<CodeBlocks>

```python
with tracer.start_as_current_span("custom_span") as span:
    span.set_attribute("confident.trace.user_id", "123")
```

```typescript
span.setAttributes({
    "confident.trace.user_id": "123",
});
```

```go
span.SetAttributes(
    attribute.String("confident.trace.user_id", "123"),
)
```

```ruby
span.setAttributes({
    "confident.trace.user_id": "123",
});
```

```csharp
span.SetAttribute("confident.trace.user_id", "123");
```

</CodeBlocks>

## Span-Level Attribute Mappings

These are the attributes specific to Confident AI spans similar to [tracing features](/docs/llm-tracing/advanced-features/attributes). The span level attributes are set in the span attributes using the `confident.span.*` namespace.

### Name

The [name](/docs/llm-tracing/advanced-features/name) of the span is displayed in the UI. You can customize it based on your liking for better UI display using the following attribute:

- `"confident.span.name"` (of type `str`) used for updating span name

<CodeBlocks>

```python
with tracer.start_as_current_span("custom_span") as span:
    span.set_attribute("confident.span.name", "custom_span")
```

```typescript
span.setAttributes({
    "confident.span.name": "custom_span",
});
```

```go
span.SetAttributes(
    attribute.String("confident.span.name", "custom_span"),
)
```

```ruby
span.setAttributes({
    "confident.span.name": "custom_span",
});
```

```csharp
span.SetAttribute("confident.span.name", "custom_span");
```

</CodeBlocks>

### Input/Output

You can set span [input and output](/docs/llm-tracing/advanced-features/input-output) at runtime using the following attributes:

- `"confident.span.input"` (of type `Any`) used for updating span input
- `"confident.span.output"` (of type `Any`) used for updating span output

<CodeBlocks>

```python
with tracer.start_as_current_span("custom_span") as span:
    span.set_attribute("confident.span.input", input)
    span.set_attribute("confident.span.output", output)
```

```typescript
span.setAttributes({
    "confident.span.input": input,
    "confident.span.output": output,
});
```

```go
span.SetAttributes(
    attribute.String("confident.span.input", input),
    attribute.String("confident.span.output", output),
)
```

```ruby
span.setAttributes({
    "confident.span.input": input,
    "confident.span.output": output,
});
```

```csharp
span.SetAttribute("confident.span.input", input);
span.SetAttribute("confident.span.output", output);
```

</CodeBlocks>

### Metric Collection

[Metric collection](/docs/metrics/metric-collections) allows you to run metrics on cloud and publish results to the observatory.

- `"confident.span.metric_collection"` (of type `str`) update the name of the metric collection for the span

<CodeBlocks>

```python
with tracer.start_as_current_span("custom_span") as span:
    span.set_attribute("confident.span.metric_collection", "<your_metric_collection>")
```

```typescript
span.setAttributes({
    "confident.span.metric_collection": "<your_metric_collection>",
});
```

```go
span.SetAttributes(
    attribute.String("confident.span.metric_collection", "<your_metric_collection>"),
)
```

```ruby
span.setAttributes({
    "confident.span.metric_collection": "<your_metric_collection>",
});
```

```csharp
span.SetAttribute("confident.span.metric_collection", "<your_metric_collection>");
```

</CodeBlocks>

### Test Case

[LLM Test Case](/docs/llm-tracing/advanced-features/test-cases) attributes can be used to unit test interactions within your LLM application. It can be set in **any span type**.

Given below is the example of running [online evaluation](/docs/llm-tracing/evaluations#online-evaluations) for a span.

<CodeBlocks>

```python
with tracer.start_as_current_span("confident_evaluation") as span:
    input = "What is the capital of France?"
    output = my_llm_app(input) # your LLM application
    
    span.set_attribute('confident.span.metric_collection', "<your_metric_collection>")
    span.set_attribute('confident.span.llm_test_case.input', input)
    span.set_attribute('confident.span.llm_test_case.actual_output', output)
```

```typescript
span.setAttributes({
    "confident.span.metric_collection": "<your_metric_collection>",
    "confident.span.llm_test_case.input": input,
    "confident.span.llm_test_case.actual_output": output,
});
```

```go
span.SetAttributes(
    attribute.String("confident.span.metric_collection", "<your_metric_collection>"),
    attribute.String("confident.span.llm_test_case.input", input),
    attribute.String("confident.span.llm_test_case.actual_output", output),
)
```

```ruby
span.setAttributes({
    "confident.span.metric_collection": "<your_metric_collection>",
    "confident.span.llm_test_case.input": input,
    "confident.span.llm_test_case.actual_output": output,
});
```

```csharp
span.SetAttribute("confident.span.metric_collection", "<your_metric_collection>");
span.SetAttribute("confident.span.llm_test_case.input", input);
span.SetAttribute("confident.span.llm_test_case.actual_output", output);
```

</CodeBlocks>

LLM test case attributes mapping:

- `"confident.span.llm_test_case.input"` (of type `str`) used for updating test case input
- `"confident.span.llm_test_case.actual_output"` (of type `str`) used for updating test case actual output
- [Optional] `"confident.span.llm_test_case.expected_output"` (of type `str`) used for updating test case expected output
- [Optional] `"confident.span.llm_test_case.context"` (of type `list[str]`) used for updating test case context
- [Optional] `"confident.span.llm_test_case.retrieval_context"` (of type `list[str]`) used for updating test case retrieval context
- [Optional] `"confident.span.llm_test_case.tools_called"` (of type `str`) used for updating test case tools called
- [Optional] `"confident.span.llm_test_case.expected_tools"` (of type `str`) used for updating test case expected tools

### Metadata

[Metadata](/docs/llm-tracing/advanced-features/metadata) can be attached to the span. This information can be used for filtering, grouping, and analyzing your spans in the observatory.

- `"confident.span.metadata"` (of type `str`) used for updating span metadata

This attribute is a JSON string which is parsed into a dictionary.

<CodeBlocks>

```python
import json
with tracer.start_as_current_span("custom_span") as span:
    span.set_attribute("confident.span.metadata", json.dumps({"key": "value"}))
```

```typescript
span.setAttributes({
    "confident.span.metadata": JSON.stringify({ key: "value" }),
});
```

```go
span.SetAttributes(
    attribute.String("confident.span.metadata", `{"key": "value"}`),
)
```

```ruby
span.setAttributes({
    "confident.span.metadata": `{"key": "value"}`,
});
```

```csharp
span.SetAttribute("confident.span.metadata", "{\"key\": \"value\"}");
```

</CodeBlocks>

### Type specific attributes

[Span types](/docs/llm-tracing/advanced-features/span-types) are optional but allow you to classify the most common types of components in LLM applications, which includes these 4 default span types:

- `llm`
- `agent`
- `retriever`
- `tool`

You can set the span type using the following attribute:

- `"confident.span.type"` (of type `str`) used for updating span type

<CodeBlocks>

```python
with tracer.start_as_current_span("custom_span") as span:
    span.set_attribute("confident.span.type", "llm")
```

```typescript
span.setAttributes({
    "confident.span.type": "llm",
});
```

```go
span.SetAttributes(
    attribute.String("confident.span.type", "llm"),
)
```

```ruby
span.setAttributes({
    "confident.span.type": "llm",
});
```

```csharp
span.SetAttribute("confident.span.type", "llm");
```

</CodeBlocks>


### Span-Level Attributes for Specific Span Types

Given below are attributes for specific span types. It is recommended to set these attributes in the span attributes using the `confident.{span_type}.*` namespace.

#### **Custom**

This is the default span type. All the attributes that we used above with `confident.span.*` namespace are applicable to this span type.

#### **LLM**

To create a LLM span, set the `confident.span.type` to `llm`. After that refer to the table below for more [LLM span attributes](/docs/llm-tracing/advanced-features/span-types#llm-span).

- `"confident.span.input"` (of type `str`, `list[str]`) used for updating LLM Span input (parsed to `list[dict]` if `list[str]` is provided)
- `"confident.span.output"` (of type `Any`) used for updating LLM Span output
- `"confident.llm.model"` (of type `str`) used for updating LLM model
- [Optional] `"confident.llm.cost_per_input_token"` (of type `float`) used for updating cost per input token
- [Optional] `"confident.llm.cost_per_output_token"` (of type `float`) used for updating cost per output token
- [Optional] `"confident.llm.input_token_count"` (of type `int`) used for updating LLM Span input token count
- [Optional] `"confident.llm.output_token_count"` (of type `int`) used for updating LLM Span output token count

Given below is the sample code for setting attributes for LLM span type.

<CodeBlocks>

```python
with tracer.start_as_current_span("llm_span") as span:
    span.set_attribute("confident.span.type", "llm")
    span.set_attribute("confident.llm.model", "gpt-3.5-turbo")
    span.set_attribute("confident.span.input", [
        json.dumps({"role": "system", "content": "You are a helpful assistant."}),
        json.dumps({"role": "user", "content": input})
    ])
    time.sleep(0.5)
    span.set_attribute("confident.span.output", "Hello world")
```

```typescript
span.setAttributes({
    "confident.span.type": "llm",
    "confident.llm.model": "gpt-3.5-turbo",
    "confident.span.input": [
        JSON.stringify({ role: "system", content: "You are a helpful assistant." }),
        JSON.stringify({ role: "user", content: "What is the capital of France?" })
    ],
    "confident.span.output": "Hello world",
});
```

```go
span.SetAttributes(
    attribute.String("confident.span.type", "llm"),
    attribute.String("confident.llm.model", "gpt-3.5-turbo"),
    attribute.StringSlice("confident.span.input", []string{
        `{"role": "system", "content": "You are a helpful assistant."}`,
        `{"role": "user", "content": "What is the capital of France?"}`,
    }),
    attribute.String("confident.span.output", "Hello world"),
)
```

```ruby
span.setAttributes({
    "confident.span.type": "llm",
    "confident.llm.model": "gpt-3.5-turbo",
    "confident.span.input": [
        `{"role": "system", "content": "You are a helpful assistant."}`,
        `{"role": "user", "content": "What is the capital of France?"}`
    ],
    "confident.span.output": "Hello world",
});
```

```csharp
span.SetAttribute("confident.span.type", "llm");
span.SetAttribute("confident.llm.model", "gpt-3.5-turbo");
span.SetAttribute("confident.span.input", [
    `{"role": "system", "content": "You are a helpful assistant."}`,
    `{"role": "user", "content": "What is the capital of France?"}`
]);
span.SetAttribute("confident.span.output", "Hello world");
```

</CodeBlocks>

#### **Agent**

To create a Agent span, set the `confident.span.type` to `agent`. After that refer to the table below for more [Agent span attributes](/docs/llm-tracing/advanced-features/span-types#agent-span).


- `"confident.agent.name"` (of type `str`) used for updating Agent span name
- [Optional] `"confident.agent.available_tools"` (of type `list[str]`) used for updating Agent span available tools
- [Optional] `"confident.agent.agent_handoffs"` (of type `list[str]`) used for updating Agent span agent handoffs
- `"confident.span.input"` (of type `Any`) used for updating Agent span input
- `"confident.span.output"` (of type `Any`) used for updating Agent span output

Given below is the sample code for setting attributes for Agent span type.

<CodeBlocks>

```python
with tracer.start_as_current_span("agent_span") as span:
    span.set_attribute("confident.span.type", "agent")
    span.set_attribute("confident.agent.name", "agent_span")
    span.set_attribute("confident.agent.available_tools", ["llm_agent", "retriever_span", "tool_span"])
    span.set_attribute("confident.agent.agent_handoffs", ["llm_agent", "retriever_span", "tool_span"])
    
    span.set_attribute("confident.span.input", json.dumps({"input": "input"}))
    span.set_attribute("confident.span.output", json.dumps({"output": "output"}))
```

```typescript
span.setAttributes({
    "confident.span.type": "agent",
    "confident.agent.name": "agent_span",
    "confident.agent.available_tools": ["llm_agent", "retriever_span", "tool_span"],
    "confident.agent.agent_handoffs": ["llm_agent", "retriever_span", "tool_span"],
    "confident.span.input": `{"input": input}`,
    "confident.span.output": `{"output": input}`,
});
```

```go
span.SetAttributes(
    attribute.String("confident.agent.name", "agent_span"),
    attribute.String("confident.agent.available_tools", []string{"llm_agent", "retriever_span", "tool_span"}),
    attribute.String("confident.agent.agent_handoffs", []string{"llm_agent", "retriever_span", "tool_span"}),
    attribute.String("confident.span.input", `{"input": "input"}`),
    attribute.String("confident.span.output", `{"output": "output"}`),
    attribute.String("confident.span.type", "agent"),
)
```

```ruby
span.setAttributes({
    "confident.span.type": "agent",
    "confident.agent.name": "agent_span",
    "confident.agent.available_tools": ["llm_agent", "retriever_span", "tool_span"],
    "confident.agent.agent_handoffs": ["llm_agent", "retriever_span", "tool_span"],
    "confident.span.input": `{"input": "input"}`,
    "confident.span.output": `{"output": "output"}`,
});
```

```csharp
span.SetAttribute("confident.span.type", "agent");
span.SetAttribute("confident.agent.name", "agent_span");
span.SetAttribute("confident.agent.available_tools", ["llm_agent", "retriever_span", "tool_span"]);
span.SetAttribute("confident.agent.agent_handoffs", ["llm_agent", "retriever_span", "tool_span"]);
span.SetAttribute("confident.span.input", `{"input": "input"}`);
span.SetAttribute("confident.span.output", `{"output": "output"}`);
```

</CodeBlocks>

#### **Tool**

To create a Tool span, set the `confident.span.type` to `tool`. After that refer to the table below for more [Tool span attributes](/docs/llm-tracing/advanced-features/span-types#tool-span).

- `"confident.tool.name"` (of type `str`) used for updating Tool span name
- [Optional] `"confident.tool.description"` (of type `str`) used for updating Tool span description
- [Optional] `"confident.span.input"` (of type `str`) used for updating Tool span input parameters (parsed to `dict` if `str` is provided)
- [Optional] `"confident.span.output"` (of type `Any`) used for updating Tool span output

Given below is the sample code for setting attributes for Tool span type.

<CodeBlocks>

```python
with tracer.start_as_current_span("tool_span") as span:
    span.set_attribute("confident.span.type", "tool")
    span.set_attribute("confident.tool.name", "tool name")

    span.set_attribute("confident.tool.description", "tool description")
    span.set_attribute("confident.span.input", json.dumps({"input": "input"}))
    span.set_attribute("confident.span.output", json.dumps({"output": "output"}))
```

```typescript
span.setAttributes({
    "confident.span.type": "tool",
    "confident.tool.name": "tool name",
    "confident.tool.description": "tool description",
    "confident.span.input": `{"input": "input"}`,
    "confident.span.output": `{"output": "output"}`,
});
```

```go
span.SetAttributes(
    attribute.String("confident.tool.name", "tool name"),
    attribute.String("confident.tool.description", "tool description"),
    attribute.String("confident.span.input", `{"input": "input"}`),
    attribute.String("confident.span.output", `{"output": "output"}`),
    attribute.String("confident.span.type", "tool"),
)
```

```ruby
span.setAttributes({
    "confident.span.type": "tool",
    "confident.tool.name": "tool name",
    "confident.tool.description": "tool description",
    "confident.span.input": `{"input": "input"}`,
    "confident.span.output": `{"output": "output"}`,
});
```

```csharp
span.SetAttribute("confident.span.type", "tool");
span.SetAttribute("confident.tool.name", "tool name");
span.SetAttribute("confident.tool.description", "tool description");
span.SetAttribute("confident.span.input", `{"input": "input"}`);
span.SetAttribute("confident.span.output", `{"output": "output"}`);
```

</CodeBlocks>

#### **Retriever**

To create a Retriever span, set the `confident.span.type` to `retriever`. After that refer to the table below for more [Retriever span attributes](/docs/llm-tracing/advanced-features/span-types#retriever-span).

- `"confident.retriever.embedder"` (of type `str`) used for updating Retrieval span embedder model
- `"confident.span.input"` (of type `str`) used for updating Retrieval span embedding input
- `"confident.retriever.retrieval_context"` (of type `list[str]`) used for updating Retrieval span retrieval context
- [Optional] `"confident.retriever.top_k"` (of type `int`) used for updating Retrieval span top k
- [Optional] `"confident.retriever.chunk_size"` (of type `int`) used for updating Retrieval span chunk size

Given below is the sample code for setting attributes for Retriever span type.

<CodeBlocks>

```python
with tracer.start_as_current_span("retriever_span") as span:
    span.set_attribute("confident.span.type", "retriever")
    span.set_attribute("confident.retriever.embedder", "embedder")

    span.set_attribute("confident.span.input", input)
    span.set_attribute("confident.retriever.retrieval_context", ["asd", "asd"])
    span.set_attribute("confident.retriever.top_k", 10)
    span.set_attribute("confident.retriever.chunk_size", 10)
```

```typescript
span.setAttributes({
    "confident.span.type": "retriever",
    "confident.retriever.embedder": "embedder",
    "confident.span.input": input,
    "confident.retriever.retrieval_context": ["asd", "asd"],
    "confident.retriever.top_k": 10,
    "confident.retriever.chunk_size": 10,
});
```

```go
span.SetAttributes(
    attribute.String("confident.retriever.embedder", "embedder"),
    attribute.String("confident.span.input", input),
    attribute.StringSlice("confident.retriever.retrieval_context", []string{"asd", "asd"}),
    attribute.Int("confident.retriever.top_k", 10),
    attribute.Int("confident.retriever.chunk_size", 10),
    attribute.String("confident.span.type", "retriever"),
)
```

```ruby
span.setAttributes({
    "confident.span.type": "retriever",
    "confident.retriever.embedder": "embedder",
    "confident.span.input": input,
    "confident.retriever.retrieval_context": new string[] { "asd", "asd" },
    "confident.retriever.top_k": 10,
    "confident.retriever.chunk_size": 10,
});
```

```csharp
span.SetAttribute("confident.retriever.embedder", "embedder");
span.SetAttribute("confident.span.input", input);
span.SetAttribute("confident.retriever.retrieval_context", new string[] { "asd", "asd" });
span.SetAttribute("confident.retriever.top_k", 10);
span.SetAttribute("confident.retriever.chunk_size", 10);
```
</CodeBlocks>