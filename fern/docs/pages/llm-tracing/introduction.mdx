---
title: Introduction to LLM Tracing
subtitle: Trace your LLM applications and evaluate them on a component level.
slug: llm-tracing/introduction
description: Learn about LLM tracing with Confident AI
---

## Overview

Confident AI offers **LLM tracing** for teams to trace and monitor LLM applications. Think Datadog for LLM apps, but with an additional suite of 30+ evaluation metrics to track continuous performance over time.

## Get Started

Get LLM tracing for your LLM app with best in-class-evals.

<CardGroup cols={3}>
  <Card
    title="5 Min Quickstart"
    icon="fa-light fa-bolt"
    iconType="solid"
    href="/llm-tracing/quickstart"
  >
    <div className='card-link-icon'>
      <Icon icon="arrow-up-right-from-square" />
    </div>

    Start tracing your LLM applications now by following this short quickstart.

  </Card>
  <Card
    title="Online & Offline Evals"
    icon="fa-light fa-toggle-on"
    iconType="solid"
    href="/llm-tracing/evaluations"
  >
    <div className='card-link-icon'>
      <Icon icon="arrow-up-right-from-square" />
    </div>

    Run online and offline evaluations for your LLM application's traces, spans and threads.

  </Card>
  <Card
    title="Latency and Cost Tracking"
    icon="fa-light fa-stopwatch"
    iconType="solid"
    href="/llm-tracing/latency-cost-tracking"
  >
    <div className='card-link-icon'>
      <Icon icon="arrow-up-right-from-square" />
    </div>

    Track your LLM application's cost and latency during execution.

  </Card>
</CardGroup>

## Advanced Features

You can configure tracing on Confident AI in virtually any way you wish:

<CardGroup cols={2}>
  <Card
    title="Trace Environments"
    icon="fa-light fa-globe"
    iconType="solid"
    href="/llm-tracing/advanced-features/environment"
  >
    <div className='card-link-icon'>
      <Icon icon="arrow-up-right-from-square" />
    </div>
    Set different trace environments for your app.
  </Card>

<Card
  title="Sampling Rate"
  icon="fa-light fa-percent"
  iconType="solid"
  href="/llm-tracing/advanced-features/sampling"
>
  <div className='card-link-icon'>
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Configure the trace sampling rate.
</Card>

<Card
  title="Any Metadata"
  icon="fa-light fa-brackets-curly"
  iconType="solid"
  href="/llm-tracing/advanced-features/metadata"
>
  <div className='card-link-icon'>
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Log any custom metadata with your traces.
</Card>

<Card
  title="Tags"
  icon="fa-light fa-tag"
  iconType="solid"
  href="/llm-tracing/advanced-features/tags"
>
  <div className='card-link-icon'>
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Log any tags for better trace organization.
</Card>

<Card
  title="Threads/Conversations"
  icon="fa-light fa-message-lines"
  iconType="solid"
  href="/llm-tracing/advanced-features/threads"
>
  <div className='card-link-icon'>
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Log entire conversations (threads) for multi-turn tracing.
</Card>

<Card
  title="Mask PII"
  icon="fa-light fa-eye-slash"
  iconType="solid"
  href="/llm-tracing/advanced-features/masking"
>
  <div className='card-link-icon'>
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Mask PII for traces to protect sensitive data.
</Card>

<Card
  title="User Tracking"
  icon="fa-light fa-user"
  iconType="solid"
  href="/llm-tracing/advanced-features/users"
>
  <div className='card-link-icon'>
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Track user identities or sessions for trace attribution.
</Card>

<Card
  title="Custom Span Types"
  icon="fa-light fa-gear"
  iconType="solid"
  href="/llm-tracing/advanced-features/attributes"
>
  <div className='card-link-icon'>
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Set span and component types for detailed tracing.
</Card>
</CardGroup>

## Integrations

You can also setup tracing via 1-line integrations.

<Note>
  Only Python is supported for itnegrations, with Typescript coming very soon.
</Note>

<CardGroup cols={3}>
  <Card
    title="OpenTelemetry"
    icon="satellite-dish"
    href="/integrations/opentelemetry"
  >
    Industry-standard observability framework for LLM monitoring.
  </Card>
  <Card
    title="OpenAI"
    icon={
      <img
        src="https://www.svgrepo.com/show/306500/openai.svg"
        alt="OpenAI logo"
      />
    }
    href="/integrations/third-party/openai"
  >
    Chat completion and responses APIs.
  </Card>
  <Card
    title="LangChain"
    icon={
      <img
        src="https://logo.svgcdn.com/s/langchain-dark-8x.png"
        alt="LangChain logo"
      />
    }
    href="/integrations/third-party/langchain"
  >
    Framework for building AI applications.
  </Card>
  <Card
    title="Pydantic AI"
    icon={
      <img
        src="https://assets.streamlinehq.com/image/private/w_300,h_300,ar_1/f_auto/v1/icons/logos/pydantic-srs7pxjs9skodrjb64x86f.png/pydantic-ae96ag6mv67bf6hz5726v8.png?_a=DATAg1AAZAA0"
        alt="Pydantic AI logo"
      />
    }
    href="/integrations/third-party/pydantic-ai"
  >
    Type-safe agent framework for Python.
  </Card>
  <Card
    title="LangGraph"
    icon={
      <img
        src="https://registry.npmmirror.com/@lobehub/icons-static-png/latest/files/light/langgraph.png"
        alt="LangGraph logo"
      />
    }
    href="/integrations/third-party/langgraph"
  >
    Graph-based framework for stateful AI applications.
  </Card>
  <Card
    title="OpenAI Agents"
    icon={
      <img
        src="https://www.svgrepo.com/show/306500/openai.svg"
        alt="OpenAI logo"
      />
    }
    href="/integrations/third-party/openai-agents"
  >
    OpenAI's agent framework for intelligent assistants.
  </Card>
  <Card
    title="LlamaIndex"
    icon={
      <img
        src="https://registry.npmmirror.com/@lobehub/icons-static-png/latest/files/light/llamaindex.png"
        alt="LlamaIndex logo"
      />
    }
    href="/integrations/third-party/llama-index"
  >
    Data framework for RAG systems and knowledge agents.
  </Card>
  <Card
    title="LiteLLM"
    icon={
      <img
        src="https://thumb.ac-illust.com/42/425e87b240c970dfc92bfb0252ea7e52_t.jpeg"
        alt="LiteLLM logo"
      />
    }
    href="/integrations/third-party/litellm"
  >
    Unified API for 100+ LLM providers.
  </Card>
  <Card
    title="Crew AI"
    icon={
      <img
        src="https://registry.npmmirror.com/@lobehub/icons-static-png/latest/files/light/crewai.png"
        alt="Crew AI logo"
      />
    }
    href="/integrations/third-party/crew-ai"
  >
    Multi-agent orchestration for collaborative AI workflows.
  </Card>
</CardGroup>

## FAQs

<AccordionGroup>
<Accordion title="What evals are offered by Confident AI LLM tracing?">

You can run evaluations using metrics for **RAG**, **agents**, **chatbots**, on:

1. Traces (end-to-end)
2. Spans (individual components)
3. Threads (multi-turn conversations)

And these are be either done in an **online** fashion (run evals as they are being ingested in the platform), or **offline** (run evals retrospectively).

</Accordion>
<Accordion title="How will tracing affect my app?">

Confident AI tracing is designed to be completely non-intrusive to your application. It:

- Can be disabled/enabled anytime through the `CONFIDENT_TRACING_ENABLED="YES"/"NO"` enviornment variable.
- Requires no rewrite of your existing code - just add the `@observe` decorator.
- Runs asynchronously in the background with zero impact on latency.
- Fails silently if there are any issues, ensuring your app keeps running.
- Works with any function signature - you can set input/output at runtime.

</Accordion>
</AccordionGroup>
