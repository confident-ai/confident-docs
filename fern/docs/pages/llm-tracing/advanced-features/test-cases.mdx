---
subtitle: LLM Tracing Test Cases
slug: llm-tracing/advanced-features/test-cases
description: Learn about test cases in LLM Tracing
---

Confident AI allows you to [run evaluations](/docs/llm-tracing/evaluations#online-evals-for-traces) on your spans and traces, which requires you to set test case parameters in `update_current_span` and `update_current_trace`.

<Note>
Each metric requires different test case parameters. For detailed information on required test case parameters for each metric, refer to the [official DeepEval documentation](https://deepeval.com/docs/metrics-introduction).
</Note>

## Test Case Parameters

Both `update_current_span` and `update_current_trace` accept 7 **OPTIONAL** test case parameters:

- `input`: The input to your LLM app
- `output`: The output of your LLM app
- `expected_output`: The expected output of your LLM app
- `retrieval_context`: A list of strings representing the retrieved text chunks from a retrieval system
- `context`: A list of strings representing the ideal retrieved text chunks provided from a retrieval system
- `tools_called`: A list of `ToolCall` objects representing the tools called by your LLM app
- `expected_tools`: A list of `ToolCall` objects representing the expected tools to be called by the LLM app

<Tip>
The **input** and **output** accept `Any` type for visualization purposes, but we recommend setting them as strings for running evaluations.
</Tip>

## Set Span Test Case Parameters

You can set span-level test case parameters in the `update_current_span` function:

<Tabs>
    <Tab title="Python">
        <CodeBlock>
            ```python title="main.py" {6}
            from deepeval.tracing import observe, update_current_span
            from deepeval.test_case import ToolCall

            @observe()
            def tool_calling_agent(query: str):
                update_current_span(
                    input=query,
                    output="Agent response",
                    tools_called=[ToolCall(name="web_search", input_parameters={"query": query})],
                )
                return "Agent response"
            
            tool_calling_agent("What is weather in San Francisco?")
            ```
        </CodeBlock>
    </Tab>
    <Tab title="Js/TypeScript">
        <CodeBlock>
            ```js title="index.ts" {5}
            import { observe, updateCurrentSpan } from "@deepeval-ts/tracing";
            import { ToolCall } from "@deepeval-ts/test-case";

            const toolCallingAgent = (query: string) => {
            updateCurrentSpan({
                input: query,
                output: "Agent response",
                toolsCalled: [new ToolCall({ name: "web_search", inputParameters: { query: query } })],
            });
            return "Agent response";
            };

            const observedToolCallingAgent = observe({ fn: toolCallingAgent });

            observedToolCallingAgent("What is weather in San Francisco?");
            ```
        </CodeBlock>
    </Tab>
</Tabs>

## Set Trace Test Case Parameters

You can set trace-level test case parameters in the `update_current_trace` function.

<Info>
`update_current_trace` can be set multiple times at any point in your code under the `observe` decorator, which is useful when a parameter is only accessible in specific parts of your code.
</Info>

<Tabs>
    <Tab title="Python">
        <CodeBlock>
            ```python title="main.py" {6}
            from openai import OpenAI
            from deepeval.tracing import observe, update_current_trace

            client = OpenAI()

            @observe()
            def retriever(query: str):
                retrieved_chunks = ["chunk1", "chunk2"]
                update_current_trace(retrieval_context=retrieved_chunks)
                return "\n".join(retrieved_chunks)
            
            @observe()
            def llm_app(query: str):
                retrieval_context = retriever(query)
                res = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": query + retrieval_context}]
                ).choices[0].message.content
                update_current_trace(input=query, output=res)
                return res
            
            llm_app("What is weather typically like in San Francisco?")
            ```
        </CodeBlock>
    </Tab>
    <Tab title="Js/TypeScript">
        <CodeBlock>
            ```js title="index.ts" {5}
            import OpenAI from "openai";
            import { observe, updateCurrentTrace } from "@deepeval-ts/tracing";

            const client = new OpenAI();

            const observedRetriever = observe({
                fn: (query: string) => {
                const retrieved_chunks = ["chunk1", "chunk2"];
                updateCurrentTrace({ retrievalContext: retrieved_chunks });
                return retrieved_chunks.join("\n");
                },
            });

            const observedLLMApp = observe({
                fn: async (query: string) => {
                const retrieval_context = observedRetriever(query);
                const res = await client.chat.completions.create({
                    model: "gpt-4o",
                    messages: [ { role: "user", content: query + retrieval_context } ],
                });
                updateCurrentTrace({ input: query, output: res.choices[0].message.content });
                return res.choices[0].message.content;
                },
            });

            observedLLMApp("What is weather typically like in San Francisco?");
            ```
        </CodeBlock>
    </Tab>
</Tabs>