---
subtitle: Learn how to set attributes while tracing your LLM application
slug: llm-tracing/advanced-features/attributes
---

## Overview

Attributes are like [`metadata`](/docs/llm-tracing/advanced-features/metadata) but specific to different span `type`s.

<Tip>
  Setting attributes will make the tracing UI easier to navigate on Confident
  AI, but is by no means required. You also cannot set attributes for custom
  [span types](/docs/llm-tracing/advanced-features/span-types).
</Tip>

## Set Attributes At Runtime

Attributes are set at runtime using update functions specific to each span type:

<Tabs>
  <Tab title="Python" language="python">
    - `update_llm_span` - `update_retriever_span`
  </Tab>
  <Tab title="TypeScript" language="typescript">
    - `updateLlmSpan` - `updateRetrieverSpan`
  </Tab>
</Tabs>

These functions update the attributes for the **CURRENT** span of the component to which the `@observe` decorator is applied. For example, `update_retriever_span` will update the attributes for `inner_function`.

<Tabs>
    <Tab title="Python" language="python">
            ```python title="main.py" {10}
            from deepeval.tracing import observe, update_retriever_span

            @observe(type="custom")
            def outer_function():

                @observe(type="retriever")
                def inner_function():

                    # Here, update_retriever_span() will update the Retriever span
                    update_retriever_span(
                        embedder="text-embedding-ada-002",
                        chunk_size=10,
                    )
            ```
    </Tab>
    <Tab title="TypeScript" language="typescript">
            ```js title="index.ts" {10}
            import { observe, updateRetrieverSpan } from "deepeval-ts/tracing";

            const observedOuterFunction = observe({
                fn: () => {
                    const observedInnerFunction = observe({
                        type: "retriever",
                        embedder: "text-embedding-ada-002",
                        fn: () => {
                            // Here, updateRetrieverSpan() will update the Retriever span
                            updateRetrieverSpan({embedder: "new embedder model", chunkSize: 10});
                        },
                    });
                    observedInnerFunction();
                },
            })
            ```
    </Tab>

</Tabs>

<Accordion title="How attributes update asynchronously">
  The current span is determined using Python's context manager, which
  automatically track the active span based on the execution context. This means
  you don't need to manually pass span references around - the system knows
  which span you're currently executing within, even in asynchronous contexts.
</Accordion>

### LLM attributes

LLM attributes track the model, prompt, and token usage and costs of language model calls. It is highly **RECOMMENDED** that you set the attributes for an LLM span.

<Tabs>
    <Tab title="Python" language="python">
        ```python title="main.py" {8}
        from deepeval.tracing import observe, update_llm_span
        
        @observe(type="llm", model="gpt-4.1")
        def generate_response(input):
            prompt = Prompt(alias="My Prompt")
            prompt.pull("00.00.01")
            output = "Generated response to: " + input
            update_llm_span(
                prompt=prompt,
                input_token_count=10,
                output_token_count=25,
                cost_per_input_token=0.01,
                cost_per_output_token=0.01,
            )
            return output
        ```

        There are **SIX** optional parameters for `update_llm_span`:

        - [Optional] `model`: The model used, of type `str`.
        - [Optional] `prompt`: The prompt of type `Prompt`, which must be pulled prior to updating the span.
        - [Optional] `input_token_count`: The number of tokens of type `float` in the input.
        - [Optional] `output_token_count`: The number of tokens of type `float` in the generated response.
        - [Optional] `cost_per_input_token`: The cost per input token of type `float`.
        - [Optional] `cost_per_output_token`: The cost per output token of type `float`.

    </Tab>
    <Tab title="TypeScript" language="typescript">
            ```typescript title="index.ts" {5}
            import { observe, updateLlmSpan } from "deepeval-ts/tracing";

            const generateResponse = (prompt: string) => {
                const output = "Generated response";
                updateLlmSpan({
                    inputTokenCount: 10,
                    outputTokenCount: 25,
                    costPerInputToken: 0,
                    costPerOutputToken: 0,
                });
                return output;
            };

            const obsetveResponse = observe({
                type: "llm",
                model: "gpt-4",
                fn: generateResponse,
            });
            ```

        There are **SIX** optional parameters for `updateLlmSpan`:

        - [Optional] `model`: The model used, of type `str`.
        - [Optional] `inputTokenCount`: The number of tokens of type `float` in the input.
        - [Optional] `outputTokenCount`: The number of tokens of type `float` in the generated response.
        - [Optional] `costPerInputToken`: The cost per input token of type `float`.
        - [Optional] `costPerOutputToken`: The cost per output token of type `float`.

    </Tab>

</Tabs>

<Note>
  The model and per-token costs can be set in the `@observe` decorator, but will
  be overridden if set in `update_llm_span`.
</Note>

### Retriever attributes

Retriever attributes track the `embedder`, `top_k`, and `chunk_size` in RAG pipelines. It is highly **RECOMMENDED** that you set the attributes for a retriever span.

<Tabs>
    <Tab title="Python" language="python">
        ```python title="main.py" {6}
        from deepeval.tracing import observe, update_retriever_span
        
        @observe(type="retriever", embedder="text-embedding-ada-002")
        def retrieve_documents(query):
            fetched_documents = ["doc1", "doc2"]
            update_retriever_span(
                embedder="text-embedding-ada-002",
                chunk_size=10,
                top_k=5,
            )
            return fetched_documents
        ```

        There are **THREE** optional parameters for `update_retriever_span`:

        - [Optional] `embedder`: The name of the embedding model used of type `str`.
        - [Optional] `chunk_size`: The size of the text chunks retrieved of type `int` from the vector store.
        - [Optional] `top_k`: The number of text chunks retrieved of type `int` from the vector store.

    </Tab>
    <Tab title="TypeScript" language="typescript">
            ```typescript title="index.ts" {5}
            import { observe, updateRetrieverSpan } from 'deepeval-ts/tracing';

            const retrieveDocuments = (query: string): string[] => {
                const fetchedDocuments = ["doc1", "doc2"];
                updateRetrieverSpan({
                    embedder: "text-embedding-ada-002",
                    chunkSize: 10,
                    topK: 5
                });
                return fetchedDocuments;
            };

            const observeDocuments = observe({ type: "retriever", embedder: "text-embedding-ada-002", fn: retrieveDocuments });
            ```

            There are **THREE** optional parameters for `updateRetrieverSpan`:

            - [Optional] `embedder`: The name of the embedding model used of type `str`.
            - [Optional] `chunkSize`: The size of the text chunks retrieved of type `int` from the vector store.
            - [Optional] `topK`: The number of text chunks retrieved of type `int` from the vector store.

    </Tab>

</Tabs>
