---
title: Simulate User Turns
subtitle: Mock user interactions with your multi-turn use cases
slug: llm-evaluation/multi-turn/simulate-user-turns
---

## Overview

Simulating user turns require:

- A multi-turn dataset of conversational goldens
- A callback function that wraps around your chatbot to the next conversation turn

<Note>
  Each conversational golden must have a `scenario` before you can simulate user
  turns. It is also highly recommended to provide a **user description** for
  higher quality simulations.
</Note>

## How it works

1. Pull your [multi-turn dataset](/llm-evaluation/dataset-management/create-goldens) from Confident AI
2. Define a callback that invokes your chatbot to generate the next conversation turn
3. Run a simulation for each golden in your dataset

## Run Simulations Locally

<Steps>
<Step title="Pull dataset">

Pull your multi-turn dataset (and [create one](/llm-evaluation/dataset-management/create-goldens) if you haven’t already):

```python main.py
from deepeval.dataset import EvaluationDataset

dataset = EvaluationDataset()
dataset.pull(alias="YOUR-DATASET-ALIAS")
```

</Step>
<Step title="Define callback">

Define a callback that wraps around your chatbot and generates the next conversation turn.

```python main.py
from deepeval.test_case import Turn
from typing import List

def chatbot_callback(input: str, turns: List[Turn], thread_id: str) -> Turn:
    messages = [{"role": turn.role, "content": turn.content} for turn in turns]
    messages.append({"role": "user", "content": input})
    response = your_chatbot(messages) # Replace with your chatbot
    return Turn(role="assistant", content=response)
```

<Info>
  The callback should accept an input, and optionally a list of `Turn`s and the
  thread id. It should return the next `Turn` in the conversation.
</Info>

</Step>
<Step title="Run simulation">

Create a [simulator](https://deepeval.com/docs/conversation-simulator) with your callback and run simulations for the goldens in your dataset.

```python main.py
from deepeval.simulator import ConversationSimulator

simulator = ConversationSimulator(model_callback=chatbot_callback)
conversational_test_cases = simulator.simulate(conversational_goldens=dataset.goldens)
```

<Success>
  The conversational test cases should now contain test cases with simulated
  conversation turns for each golden in your dataset.
</Success>

</Step>

</Steps>

## Run Simulations Remotely

<Steps>
<Step title="Pull dataset">

Pull your multi-turn dataset as you would with local simulations:

<Tabs>

<Tab title="Python" language="python">

```python main.py
from deepeval.dataset import EvaluationDataset

dataset = EvaluationDataset()
dataset.pull(alias="YOUR-DATASET-ALIAS")
```

</Tab>

<Tab title="Typescript" language="typescript">

```ts index.ts
import { EvaluationDataset } from "deepeval-ts";

const dataset = new EvaluationDataset();
await dataset.pull({ alias: "YOUR-DATASET-ALIAS" });
```

</Tab>

<Tab title="cURL" language="curl">

<EndpointRequestSnippet endpoint="GET /v1/datasets/{alias}" />

</Tab>

</Tabs>

</Step>

<Step title="Simulate turns">

<Tabs>

<Tab title="Python" language="python">

Set `run_remote` to true to run simulations remotely.

```python main.py {3}
from deepeval.simulator import ConversationSimulator

simulator = ConversationSimulator(model_callback=chatbot_callback, run_remote=True)
conversational_test_cases = simulator.simulate(conversational_goldens=dataset.goldens)
```

</Tab>

<Tab title="Typescript" language="typescript">

Only remote simluation is available in typescript.

```ts index.ts
import { ConversationalGolden, ConversationSimulator, EvaluationDataset } from "deepeval-ts";

const dataset = new EvaluationDataset();
await dataset.pull({ alias: "YOUR-DATASET-ALIAS" });

const simulator = new ConversationSimulator({
  modelCallback: chatbotCallback,
});

const results = await simulator.simulate({
  conversationalGoldens: dataset.goldens as ConversationalGolden[],
});
```

<Accordion title="Click to see example callback in Typescript">

```typescript
const chatbotCallback = async (args: {
  input: string;
  turns: Turn[];
  threadId: string;
}): Promise<Turn> => {
  return new Turn({
    role: "assistant",
    content: your_chatbot(args.input),
  });
};
```

</Accordion>

</Tab>

<Tab title="cURL" language="curl">
Use `/v1/simulate` to generate the first user turn for each golden.

```curl
curl -X POST https://api.confident-ai.com/v1/simulate \
     -H "CONFIDENT_API_KEY: <PROJECT-API-KEY>" \
     -H "Content-Type: application/json" \
     -d '{
  "golden": [{
    "scenario": "A frustrated user asking for a refund.",
    "userDescription": "A white male who is a customer for over 2 years."
  }],
}'
```

Continue calling `/v1/simulate` until you’ve simulated the desired number of turns.

<Note>
  The `/v1/simulate` endpoint returns the **next user turn**. You should add
  this turn to your golden, append the chatbot’s response, and then call the
  endpoint again.
</Note>

```curl
curl -X POST https://api.confident-ai.com/v1/simulate \
     -H "CONFIDENT_API_KEY: <PROJECT-API-KEY>" \
     -H "Content-Type: application/json" \
     -d '{
  "golden": [{
    "scenario": "A frustrated user asking for a refund.",
    "userDescription": "A white male who is a customer for over 2 years.",
    "turns": [
      {"role": "user", "content": "Hi"},
      {"role": "assistant", "content": "Hello! How can I help you today?"}
    ]
  }],

}'

```

<Warning>
  `/v1/simulate` will fail if the role of the last turn is not `assistant`, if
  turns is provided.
</Warning>

</Tab>

</Tabs>

</Step>

</Steps>

## Advanced Usage

### Early stopping

To stop a simulation naturally before it reaches the maximum number of turns, you can provide the `expected_outcome` for each golden, which will end the conversation automatically after the expected outcome has been reached.

<Tabs>

<Tab title="Python" language="python">

```python main.py
from deepeval.dataset import ConversationalGolden

conversation_golden = ConversationalGolden(
    scenario="Andy Byron wants to purchase a VIP ticket to a cold play concert.",
    expected_outcome="Successful purchase of a ticket.",
    user_description="Andy Byron is the CEO of Astronomer.",
)
```

<Note>
  If `expected_outcome` is unavalaible, the `max_user_simulations` parameter in
  the `simluate` method will stop simulation after a certain number of user
  turns, which is defaulted to 10.
</Note>

</Tab>

<Tab title="Typescript" language="typescript">

```ts index.ts
import { ConversationalGolden } from "deepeval-ts";

const conversationGolden = new ConversationalGolden({
  scenario: "Andy Byron wants to purchase a VIP ticket to a cold play concert.",
  expectedOutcome: "Successful purchase of a ticket.",
  userDescription: "Andy Byron is the CEO of Astronomer.",
});
```

</Tab>

<Tab title="cURL" language="curl">

If the expected outcome is provided and reached during simulation, the
conversation will be marked as complete in the response to `/v1/simulate`.

```curl
curl -X POST https://api.confident-ai.com/v1/simulate \
     -H "CONFIDENT_API_KEY: <PROJECT-API-KEY>" \
     -H "Content-Type: application/json" \
     -d '{
  "golden": [{
    "scenario": "Andy Byron wants to purchase a VIP ticket to a cold play concert.",
    "userDescription": "Andy Byron is the CEO of Astronomer.",
    "expectedOutcome": "Successful purchase of a ticket."
  }],
  "callback": "https://your-callback-endpoint.com/simulate"
}'
```

</Tab>

</Tabs>

### Extending existing conversations

You can extend existing conversations by providing existing `Turn`s to each golden in your dataset. The simulator will automatically detect and continue simulating from the existing turns.

<Tabs>

<Tab title="Python" language="python">

```python main.py
from deepeval.dataset import ConversationalGolden
from deepeval.test_case import Turn

conversation_golden = ConversationalGolden(
    scenario="Andy Byron wants to purchase a VIP ticket to a cold play concert.",
    user_description="Andy Byron is the CEO of Astronomer.",
    turns=[
        Turn(role="user", content="Hi"),
        Turn(role="assistant", content="Hello! How can I help you today?"),
        Turn(role="user", content="I want to purchase a VIP ticket to a cold play concert."),
    ]
)
```

</Tab>

<Tab title="Typescript" language="typescript">

```ts index.ts
import { ConversationalGolden, Turn } from "deepeval-ts";

const firstTurn = new Turn({
  role: "user",
  content: "Hi",
});
const secondTurn = new Turn({
  role: "assistant",
  content: "Hello! How can I help you today?",
});
const thirdTurn = new Turn({
  role: "user",
  content: "I want to purchase a VIP ticket to a cold play concert.",
});

const conversationGolden = new ConversationalGolden({
  scenario: "Andy Byron wants to purchase a VIP ticket to a cold play concert.",
  userDescription: "Andy Byron is the CEO of Astronomer.",
  turns: [firstTurn, secondTurn, thirdTurn],
});
```

</Tab>

<Tab title="cURL" language="curl">

```curl
curl -X POST https://api.confident-ai.com/v1/simulate \
     -H "CONFIDENT_API_KEY: <PROJECT-API-KEY>" \
     -H "Content-Type: application/json" \
     -d '{
  "golden": [{
    "scenario": "Andy Byron wants to purchase a VIP ticket to a cold play concert.",
    "userDescription": "Andy Byron is the CEO of Astronomer.",
    "turns": [
      {"role": "user", "content": "Hi"},
      {"role": "assistant", "content": "Hello! How can I help you today?"},
    ]
  }],
}'
```

</Tab>

</Tabs>
