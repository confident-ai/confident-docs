---
title: Multi-Turn Evals
subtitle: Simulate conversations and run end-to-end testing for multi-turn use cases
slug: llm-evaluation/code-driven/multi-turn
---

## Overview

Multi-turn evaluation requires:

- A multi-turn dataset of conversational goldens
- A callback function that wraps around your chatbot to generate conversation turns
- A list of multi-turn metrics you wish to evaluate with

<Note>
  Each conversational golden must have a `scenario` before you can simulate user
  turns. It is also highly recommended to provide a **user description** for
  higher quality simulations.
</Note>

## How It Works

1. Pull your [multi-turn dataset](/llm-evaluation/dataset-management/manage-datasets) from Confident AI
2. Define a callback that invokes your chatbot to generate conversation turns
3. Simulate conversations for each golden in your dataset
4. Run evaluation on the resulting test cases

## Define Your Callback

Define a callback that wraps around your chatbot and generates the next conversation turn:

```python callback.py
from deepeval.test_case import Turn
from typing import List

def chatbot_callback(input: str, turns: List[Turn], thread_id: str) -> Turn:
    messages = [{"role": turn.role, "content": turn.content} for turn in turns]
    messages.append({"role": "user", "content": input})
    response = your_chatbot(messages) # Replace with your chatbot
    return Turn(role="assistant", content=response)
```

<Info>
  The callback should accept an input, and optionally a list of `Turn`s and the
  thread id. It should return the next `Turn` in the conversation.
</Info>

## Run Evals Locally

Running evals locally is only possible with the Python `deepeval` library. For Typescript or other languages, skip to [remote evals](#run-evals-remotely).

<Steps>

<Step title="Pull dataset">

Pull your multi-turn dataset (and [create one](/llm-evaluation/dataset-management/using-datasets) if you haven't already):

```python main.py
from deepeval.dataset import EvaluationDataset

dataset = EvaluationDataset()
dataset.pull(alias="YOUR-DATASET-ALIAS")
```

</Step>

<Step title="Simulate conversations">

Create a [simulator](https://deepeval.com/docs/conversation-simulator) with your callback and generate test cases from your goldens:

```python main.py
from deepeval.simulator import ConversationSimulator

simulator = ConversationSimulator(model_callback=chatbot_callback)
for golden in dataset.goldens:
    test_case = simulator.simulator(golden)
    dataset.add_test_case(test_case)
```

<Note>
  You can also use any other means to generate `turns` in a
  `ConversationalTestCase` and map golden properties manually.
</Note>

</Step>

<Step title="Run evaluation">

The `evaluate()` function runs your test suite and uploads results to Confident AI:

```python main.py
from deepeval.metrics import TurnRelevancyMetric
from deepeval import evaluate

# Replace with your metrics
evaluate(test_cases=dataset.test_cases, metrics=[TurnRelevancyMetric()])
```

Done! You should see a link to your newly created sharable testing report.

- Each metric is applied to every test case (e.g., 10 test cases Ã— 2 metrics = 20 evaluations)
- A test case passes only if all metrics for it pass
- The test run's pass rate is the proportion of test cases that pass

<Tip>
  `deepeval` opens your browser automatically by default. To disable this
  behavior, set `CONFIDENT_BROWSER_OPEN=NO`.
</Tip>

<Frame caption="Multi-Turn Testing Reports">

<video
  autoPlay
  controls
  muted
  data-video="evaluation.multiTurnReport"
  type="video/mp4"
/>

</Frame>

</Step>

</Steps>

## Run Evals Remotely

<Steps>

<Step title="Create metric collection">

Go to **Project** > **Metric** > **Collections**:

<Frame caption="Metric Collection for Remote Evals" background="subtle">

<video
  autoPlay
  loop
  muted
  data-video="metrics.createCollection"
  type="video/mp4"
/>

</Frame>

<Warning>Don't forget to create a multi-turn collection.</Warning>

</Step>

<Step title="Pull dataset and simulate conversations">

<Tabs>

<Tab title="Python" language="python">

Set `run_remote` to true to run simulations remotely:

```python main.py
from deepeval.simulator import ConversationSimulator
from deepeval.dataset import EvaluationDataset

dataset = EvaluationDataset()
dataset.pull(alias="YOUR-DATASET-ALIAS")

simulator = ConversationSimulator(model_callback=chatbot_callback, run_remote=True)
for golden in dataset.goldens:
    test_case = simulator.simulator(golden)
    dataset.add_test_case(test_case)
```

</Tab>

<Tab title="Typescript" language="typescript">

```ts index.ts
import {
  ConversationalGolden,
  ConversationSimulator,
  EvaluationDataset,
} from "deepeval-ts";

const dataset = new EvaluationDataset();
await dataset.pull({ alias: "YOUR-DATASET-ALIAS" });

const simulator = new ConversationSimulator({ modelCallback: chatbotCallback });
const testCases = await simulator.simulate({
  conversationalGoldens: dataset.goldens as ConversationalGolden[],
});

for (const testCase of testCases) {
  dataset.addTestCase(testCase);
}
```

<Accordion title="Click to see example callback in Typescript">

```typescript
const chatbotCallback = async (args: {
  input: string;
  turns: Turn[];
  threadId: string;
}): Promise<Turn> => {
  return new Turn({
    role: "assistant",
    content: your_chatbot(args.input),
  });
};
```

</Accordion>

</Tab>

<Tab title="cURL" language="curl">

Use `/v1/simulate` to generate the first user turn for each golden:

```curl
curl -X POST https://api.confident-ai.com/v1/simulate \
     -H "CONFIDENT_API_KEY: <PROJECT-API-KEY>" \
     -H "Content-Type: application/json" \
     -d '{
  "golden": [{
    "scenario": "A frustrated user asking for a refund.",
    "userDescription": "A white male who is a customer for over 2 years."
  }]
}'
```

Continue calling `/v1/simulate` until you've simulated the desired number of turns.

<Note>
  The `/v1/simulate` endpoint returns the **next user turn**. You should add
  this turn to your golden, append the chatbot's response, and then call the
  endpoint again.
</Note>

<Warning>
  `/v1/simulate` will fail if the role of the last turn is not `assistant`, if
  turns is provided.
</Warning>

</Tab>

</Tabs>

</Step>

<Step title="Run evaluation">

<Tabs>

<Tab title="Python" language="python">

```python main.py
from deepeval import evaluate

evaluate(test_case=dataset.test_cases, metric_collection="YOUR-COLLECTION-NAME")
```

</Tab>

<Tab title="Typescript" language="typescript">

```ts index.ts
import {
  ConversationalTestCase,
  evaluate,
  EvaluationDataset,
} from "deepeval-ts";

const dataset = new EvaluationDataset();
dataset.pull({ alias: "YOUR-DATASET-ALIAS" });

evaluate({
  conversationalTestCases: dataset.testCases as ConversationalTestCase[],
  metricCollection: "YOUR-COLLECTION-NAME",
});
```

</Tab>

<Tab title="cURL" language="curl">

<EndpointRequestSnippet endpoint="POST /v1/evaluate" example="Multi-Turn" />

</Tab>

</Tabs>

</Step>

</Steps>

## Advanced Usage

### Early Stopping

To stop a simulation naturally before it reaches the maximum number of turns, provide an `expected_outcome` for each golden. The conversation will end automatically after the expected outcome has been reached.

<Tabs>

<Tab title="Python" language="python">

```python main.py
from deepeval.dataset import ConversationalGolden

conversation_golden = ConversationalGolden(
    scenario="Andy Byron wants to purchase a VIP ticket to a cold play concert.",
    expected_outcome="Successful purchase of a ticket.",
    user_description="Andy Byron is the CEO of Astronomer.",
)
```

<Note>
  If `expected_outcome` is unavailable, the `max_user_simulations` parameter in
  the `simulate` method will stop simulation after a certain number of user
  turns, which defaults to 10.
</Note>

</Tab>

<Tab title="Typescript" language="typescript">

```ts index.ts
import { ConversationalGolden } from "deepeval-ts";

const conversationGolden = new ConversationalGolden({
  scenario: "Andy Byron wants to purchase a VIP ticket to a cold play concert.",
  expectedOutcome: "Successful purchase of a ticket.",
  userDescription: "Andy Byron is the CEO of Astronomer.",
});
```

</Tab>

<Tab title="cURL" language="curl">

If the expected outcome is provided and reached during simulation, the
conversation will be marked as complete in the response to `/v1/simulate`.

```curl
curl -X POST https://api.confident-ai.com/v1/simulate \
     -H "CONFIDENT_API_KEY: <PROJECT-API-KEY>" \
     -H "Content-Type: application/json" \
     -d '{
  "golden": [{
    "scenario": "Andy Byron wants to purchase a VIP ticket to a cold play concert.",
    "userDescription": "Andy Byron is the CEO of Astronomer.",
    "expectedOutcome": "Successful purchase of a ticket."
  }],
  "callback": "https://your-callback-endpoint.com/simulate"
}'
```

</Tab>

</Tabs>

### Extending Existing Conversations

You can extend existing conversations by providing existing `Turn`s to each golden. The simulator will automatically detect and continue simulating from the existing turns.

<Tabs>

<Tab title="Python" language="python">

```python main.py
from deepeval.dataset import ConversationalGolden
from deepeval.test_case import Turn

conversation_golden = ConversationalGolden(
    scenario="Andy Byron wants to purchase a VIP ticket to a cold play concert.",
    user_description="Andy Byron is the CEO of Astronomer.",
    turns=[
        Turn(role="user", content="Hi"),
        Turn(role="assistant", content="Hello! How can I help you today?"),
        Turn(role="user", content="I want to purchase a VIP ticket to a cold play concert."),
    ]
)
```

</Tab>

<Tab title="Typescript" language="typescript">

```ts index.ts
import { ConversationalGolden, Turn } from "deepeval-ts";

const firstTurn = new Turn({
  role: "user",
  content: "Hi",
});
const secondTurn = new Turn({
  role: "assistant",
  content: "Hello! How can I help you today?",
});
const thirdTurn = new Turn({
  role: "user",
  content: "I want to purchase a VIP ticket to a cold play concert.",
});

const conversationGolden = new ConversationalGolden({
  scenario: "Andy Byron wants to purchase a VIP ticket to a cold play concert.",
  userDescription: "Andy Byron is the CEO of Astronomer.",
  turns: [firstTurn, secondTurn, thirdTurn],
});
```

</Tab>

<Tab title="cURL" language="curl">

```curl
curl -X POST https://api.confident-ai.com/v1/simulate \
     -H "CONFIDENT_API_KEY: <PROJECT-API-KEY>" \
     -H "Content-Type: application/json" \
     -d '{
  "golden": [{
    "scenario": "Andy Byron wants to purchase a VIP ticket to a cold play concert.",
    "userDescription": "Andy Byron is the CEO of Astronomer.",
    "turns": [
      {"role": "user", "content": "Hi"},
      {"role": "assistant", "content": "Hello! How can I help you today?"}
    ]
  }]
}'
```

</Tab>

</Tabs>
